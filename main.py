import urllib.robotparser
import urllib.parse
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import pandas as pd
from selenium.webdriver.support.ui import Select, WebDriverWait
from bs4 import BeautifulSoup
from selenium.webdriver.chrome.options import Options

# ğŸ¤– robots.txt í™•ì¸ ë° ê°•ì œ ì ìš©
def check_robots_txt(url):
    """robots.txtë¥¼ í™•ì¸í•˜ì—¬ í¬ë¡¤ë§ í—ˆìš© ì—¬ë¶€ë¥¼ ì²´í¬"""
    try:
        # robots.txt íŒŒì„œ ìƒì„±
        rp = urllib.robotparser.RobotFileParser()
        
        # ë„ë©”ì¸ì—ì„œ robots.txt URL ìƒì„±
        parsed_url = urllib.parse.urlparse(url)
        robots_url = f"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt"
        
        print(f"ğŸ” ì›¹ í¬ë¡¤ë§ í—ˆê°€ í™•ì¸: {robots_url}")
        print("   ğŸ“– robots.txt íŒŒì¼ì„ ì½ì–´ì„œ í¬ë¡¤ë§ì´ í—ˆìš©ë˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # robots.txt ì½ê¸°
        rp.set_url(robots_url)
        rp.read()
        
        # í¬ë¡¤ë§ í—ˆìš© ì—¬ë¶€ í™•ì¸ (* = ëª¨ë“  User-agent)
        can_fetch = rp.can_fetch("*", url)
        
        if can_fetch:
            print(f"âœ… í¬ë¡¤ë§ í—ˆê°€ í™•ì¸ ì™„ë£Œ!")
            print(f"   ğŸ“„ í•´ë‹¹ í˜ì´ì§€ëŠ” í¬ë¡¤ë§ì´ í—ˆìš©ë©ë‹ˆë‹¤: /Record/ ê²½ë¡œ")
            return True
        else:
            print(f"âŒ í¬ë¡¤ë§ ê¸ˆì§€ í˜ì´ì§€ì…ë‹ˆë‹¤!")
            print(f"   ğŸš« robots.txtì—ì„œ ì´ URLì˜ í¬ë¡¤ë§ì„ ê¸ˆì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"âš ï¸  robots.txt í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   ğŸ’­ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ robots.txtë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return False

# ğŸ›¡ï¸ í¬ë¡¤ë§ ì—í‹°ì¼“ ì„¤ì •
DELAY_BETWEEN_REQUESTS = 2.0
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

print("ğŸ¤– KBO íƒ€ì ê¸°ë¡ í¬ë¡¤ëŸ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")
print("ğŸ“Š 2025ë…„ í˜„ì¬ ì‹œì¦Œ ëª¨ë“  íŒ€ì˜ íƒ€ì ê¸°ë¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
print("ğŸ¯ êµìœ¡/ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤")
print("=" * 60)

# í¬ë¡¤ë§ ëŒ€ìƒ URL
target_url = 'https://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx?sort=HRA_RT'

print("\nğŸš¨ 1ë‹¨ê³„: í¬ë¡¤ë§ í—ˆê°€ í™•ì¸")
print("   ğŸ’¡ ì›¹ì‚¬ì´íŠ¸ì˜ robots.txtë¥¼ í™•ì¸í•´ì„œ í¬ë¡¤ë§ì´ í—ˆìš©ë˜ëŠ”ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤")

# ğŸš¨ robots.txt ê°•ì œ í™•ì¸
if not check_robots_txt(target_url):
    print("\nğŸ›‘ í¬ë¡¤ë§ì´ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
    print("ğŸ“– ìì„¸í•œ ë‚´ìš©: https://www.koreabaseball.com/robots.txt")
    exit(1)  # í”„ë¡œê·¸ë¨ ê°•ì œ ì¢…ë£Œ

print("\nâ° 2ë‹¨ê³„: ì•ˆì „í•œ í¬ë¡¤ë§ ì„¤ì •")
print("   ğŸ›¡ï¸  KBO ì„œë²„ì— ë¬´ë¦¬ê°€ ê°€ì§€ ì•Šë„ë¡ ìš”ì²­ ê°„ê²©ì„ 2ì´ˆë¡œ ì„¤ì •í•©ë‹ˆë‹¤")
print("   ğŸŒ ì •ìƒì ì¸ ì›¹ë¸Œë¼ìš°ì €ë¡œ ì¸ì‹ë˜ë„ë¡ User-Agentë¥¼ ì„¤ì •í•©ë‹ˆë‹¤")

# í¬ë¡¬ ì˜µì…˜ ì„¤ì •
chrome_options = Options()
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument(f"--user-agent={USER_AGENT}")

print("\nğŸš€ 3ë‹¨ê³„: í¬ë¡¬ ë¸Œë¼ìš°ì € ì‹¤í–‰")
print("   ğŸ’» ìë™í™”ëœ í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")

# í¬ë¡¬ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(options=chrome_options)
driver.implicitly_wait(10)

wait = WebDriverWait(driver, 10)

print("   âœ… í¬ë¡¬ ë¸Œë¼ìš°ì €ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")
print("   ğŸ’¡ Chrome DevTools ë©”ì‹œì§€ëŠ” ì •ìƒì ì¸ ë¸Œë¼ìš°ì € ì‹¤í–‰ ë¡œê·¸ì…ë‹ˆë‹¤ (ë¬´ì‹œí•˜ì…”ë„ ë©ë‹ˆë‹¤)")

print(f"\nğŸŒ 4ë‹¨ê³„: KBO ê³µì‹ í™ˆí˜ì´ì§€ ì ‘ì†")
print(f"   ğŸ”— ì ‘ì† ì¤‘: {target_url}")

# robots.txt í™•ì¸ í†µê³¼ í›„ì—ë§Œ ì ‘ì†
driver.get(target_url)

print("   âœ… KBO íƒ€ì ê¸°ë¡ í˜ì´ì§€ì— ì„±ê³µì ìœ¼ë¡œ ì ‘ì†í–ˆìŠµë‹ˆë‹¤!")

# ğŸ›¡ï¸ ì•ˆì „í•œ ëŒ€ê¸° í•¨ìˆ˜
def safe_sleep():
    """ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì ì ˆí•œ ëŒ€ê¸°"""
    time.sleep(DELAY_BETWEEN_REQUESTS)
    print("     â³ ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ 2ì´ˆ ëŒ€ê¸° ì¤‘...")

def create_table(driver):
    kbo_page = driver.page_source
    soup = BeautifulSoup(kbo_page, 'html.parser')
    table = soup.select_one('#cphContents_cphContents_cphContents_udpContent > div.record_result > table')
    table = pd.read_html(str(table), flavor='html5lib')[0]
    return table

def team_list(driver):
    safe_sleep()
    combobox = driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ddlTeam_ddlTeam')
    safe_sleep()
    options = combobox.find_elements(By.TAG_NAME, 'option')[1:]
    teams = [option.text for option in options]
    return teams

def page_click(driver):
    df1 = create_table(driver)
    page_count = len(driver.find_elements(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_udpContent > div.record_result > div > a'))
    if page_count > 1:
        print("     ğŸ“„ 2í˜ì´ì§€ê°€ ìˆì–´ì„œ ì¶”ê°€ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
        driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ucPager_btnNo2').click()
        df2 = create_table(driver)
        safe_sleep()
        driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ucPager_btnNo1').click()
        df = pd.concat([df1, df2])
    else:
        df1
    return df

# ë©”ì¸ í¬ë¡¤ë§ ë¡œì§ - í˜„ì¬ ì‹œì¦Œ(2025)ë§Œ ìˆ˜ì§‘
dfs = []
current_season = "2025"  # ğŸ¯ í˜„ì¬ ì‹œì¦Œë§Œ!

print(f"\nğŸ“… 5ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
print(f"   ğŸ¯ ìˆ˜ì§‘ ëŒ€ìƒ: {current_season}ì‹œì¦Œ KBO ì „ì²´ íŒ€ íƒ€ì ê¸°ë¡")

print(f"\nğŸ—“ï¸  {current_season}ì‹œì¦Œ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
safe_sleep()

# ì‹œì¦Œ ì„ íƒ
season_combo = driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ddlSeason_ddlSeason')
season_combo = Select(season_combo)
season_combo.select_by_value(current_season)
teams = team_list(driver)

print(f"âš¾ ë°œê²¬ëœ íŒ€ ëª©ë¡: {len(teams)}ê°œ")
print(f"   ğŸ“‹ {', '.join(teams)}")
print(f"\nğŸ”„ ê° íŒ€ë³„ë¡œ ì„ ìˆ˜ ê¸°ë¡ì„ ì°¨ë¡€ëŒ€ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")

for team_idx, team in enumerate(teams, 1):
    print(f"\n   ğŸŸï¸  [{team_idx:2d}/{len(teams)}] {team} íŒ€ ì„ ìˆ˜ ê¸°ë¡ ìˆ˜ì§‘ ì¤‘...")
    safe_sleep()
    
    combobox = driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ddlTeam_ddlTeam')
    team_combo = Select(combobox)
    team_combo.select_by_visible_text(team)
    safe_sleep()
    
    df = page_click(driver)
    df['year'] = current_season
    dfs.append(df)
    print(f"     âœ… {team} íŒ€ {len(df)}ëª… ì„ ìˆ˜ ê¸°ë¡ ìˆ˜ì§‘ ì™„ë£Œ!")

# ê²°ê³¼ ì²˜ë¦¬
print(f"\nğŸ“Š 6ë‹¨ê³„: ìˆ˜ì§‘ ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥")
if dfs:
    result = pd.concat(dfs, ignore_index=True)
    print(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ!")
    print(f"   ğŸ“ˆ ì´ {len(result)}ëª…ì˜ ì„ ìˆ˜ ê¸°ë¡ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤ ({current_season}ì‹œì¦Œ)")
    
    try:
        print(f"\nğŸ“‹ ìˆ˜ì§‘ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ëª…):")
        print("=" * 80)
        print(result.head(10).to_string(index=False))
    except Exception:
        print(result.head(10))
        
    filename = f'kbo_hitters_{current_season}.csv'
    result.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
    print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {filename}")
    print(f"   ğŸ“Š ì—‘ì…€ì—ì„œë„ ì—´ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    
else:
    print('âŒ ì˜¤ë¥˜: ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    print('   ğŸ’­ ì¸í„°ë„· ì—°ê²°ì´ë‚˜ KBO í™ˆí˜ì´ì§€ ìƒíƒœë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.')

print(f"\nğŸ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print(f"   ğŸ¤– í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ìë™ìœ¼ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤...")
driver.quit()
print(f"   âœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
print(f"   ğŸ‰ {current_season}ì‹œì¦Œ KBO íƒ€ì ê¸°ë¡ì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")