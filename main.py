import urllib.robotparser
import urllib.parse
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import pandas as pd
from selenium.webdriver.support.ui import Select, WebDriverWait
from bs4 import BeautifulSoup
from selenium.webdriver.chrome.options import Options

# ğŸ¤– robots.txt í™•ì¸ ë° ê°•ì œ ì ìš©
def check_robots_txt(url):
    """robots.txtë¥¼ í™•ì¸í•˜ì—¬ í¬ë¡¤ë§ í—ˆìš© ì—¬ë¶€ë¥¼ ì²´í¬"""
    try:
        # robots.txt íŒŒì„œ ìƒì„±
        rp = urllib.robotparser.RobotFileParser()
        
        # ë„ë©”ì¸ì—ì„œ robots.txt URL ìƒì„±
        parsed_url = urllib.parse.urlparse(url)
        robots_url = f"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt"
        
        print(f"ğŸ” robots.txt í™•ì¸ ì¤‘: {robots_url}")
        
        # robots.txt ì½ê¸°
        rp.set_url(robots_url)
        rp.read()
        
        # í¬ë¡¤ë§ í—ˆìš© ì—¬ë¶€ í™•ì¸ (* = ëª¨ë“  User-agent)
        can_fetch = rp.can_fetch("*", url)
        
        if can_fetch:
            print(f"âœ… robots.txt í—ˆìš©: {url}")
            return True
        else:
            print(f"âŒ robots.txt ê¸ˆì§€: {url}")
            print("ğŸš« ì´ URLì€ í¬ë¡¤ë§ì´ ê¸ˆì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"âš ï¸  robots.txt í™•ì¸ ì‹¤íŒ¨: {e}")
        print("âš ï¸  ìˆ˜ë™ìœ¼ë¡œ robots.txtë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        return False

# ğŸ›¡ï¸ í¬ë¡¤ë§ ì—í‹°ì¼“ ì„¤ì •
DELAY_BETWEEN_REQUESTS = 2.0
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

print("ğŸ¤– KBO í¬ë¡¤ëŸ¬ ì‹œì‘ - êµìœ¡/ì—°êµ¬ ëª©ì  (í˜„ì¬ ì‹œì¦Œ)")
print("=" * 50)

# í¬ë¡¤ë§ ëŒ€ìƒ URL
target_url = 'https://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx?sort=HRA_RT'

# ğŸš¨ robots.txt ê°•ì œ í™•ì¸
if not check_robots_txt(target_url):
    print("\nğŸ›‘ robots.txtì— ì˜í•´ í¬ë¡¤ë§ì´ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
    print("ğŸ“– https://www.koreabaseball.com/robots.txt ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    exit(1)  # í”„ë¡œê·¸ë¨ ê°•ì œ ì¢…ë£Œ

print("â° ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì¶©ë¶„í•œ ì§€ì—°ì‹œê°„ì„ ì„¤ì •í•©ë‹ˆë‹¤...")

# í¬ë¡¬ ì˜µì…˜ ì„¤ì •
chrome_options = Options()
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument(f"--user-agent={USER_AGENT}")

# í¬ë¡¬ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(options=chrome_options)
driver.implicitly_wait(10)

wait = WebDriverWait(driver, 10)

# robots.txt í™•ì¸ í†µê³¼ í›„ì—ë§Œ ì ‘ì†
driver.get(target_url)

# ğŸ›¡ï¸ ì•ˆì „í•œ ëŒ€ê¸° í•¨ìˆ˜
def safe_sleep():
    """ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì ì ˆí•œ ëŒ€ê¸°"""
    time.sleep(DELAY_BETWEEN_REQUESTS)
    print("â³ ëŒ€ê¸° ì¤‘... (ì„œë²„ ë¶€í•˜ ë°©ì§€)")

def create_table(driver):
    kbo_page = driver.page_source
    soup = BeautifulSoup(kbo_page, 'html.parser')
    table = soup.select_one('#cphContents_cphContents_cphContents_udpContent > div.record_result > table')
    table = pd.read_html(str(table), flavor='html5lib')[0]
    return table

def team_list(driver):
    safe_sleep()
    combobox = driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ddlTeam_ddlTeam')
    safe_sleep()
    options = combobox.find_elements(By.TAG_NAME, 'option')[1:]
    teams = [option.text for option in options]
    return teams

def page_click(driver):
    df1 = create_table(driver)
    page_count = len(driver.find_elements(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_udpContent > div.record_result > div > a'))
    if page_count > 1:
        driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ucPager_btnNo2').click()
        df2 = create_table(driver)
        safe_sleep()
        driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ucPager_btnNo1').click()
        df = pd.concat([df1, df2])
    else:
        return df1
    return df

# ë©”ì¸ í¬ë¡¤ë§ ë¡œì§ - í˜„ì¬ ì‹œì¦Œ(2025)ë§Œ ìˆ˜ì§‘
dfs = []
current_season = "2025"  # ğŸ¯ í˜„ì¬ ì‹œì¦Œë§Œ!

print(f"ğŸ“… ìˆ˜ì§‘ ëŒ€ìƒ: {current_season} ì‹œì¦Œ (í˜„ì¬ ì‹œì¦Œ)")

print(f"\nğŸ—“ï¸  ì‹œì¦Œ {current_season} ìˆ˜ì§‘ ì¤‘...")
safe_sleep()

# ì‹œì¦Œ ì„ íƒ
season_combo = driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ddlSeason_ddlSeason')
season_combo = Select(season_combo)
season_combo.select_by_value(current_season)
teams = team_list(driver)

print(f"âš¾ ì´ {len(teams)}ê°œ íŒ€ ë°œê²¬: {', '.join(teams)}")

for team_idx, team in enumerate(teams, 1):
    print(f"   ğŸŸï¸  {team} íŒ€ ìˆ˜ì§‘ ì¤‘... ({team_idx}/{len(teams)})")
    safe_sleep()
    
    combobox = driver.find_element(By.CSS_SELECTOR, '#cphContents_cphContents_cphContents_ddlTeam_ddlTeam')
    team_combo = Select(combobox)
    team_combo.select_by_visible_text(team)
    safe_sleep()
    
    df = page_click(driver)
    df['year'] = current_season
    dfs.append(df)

# ê²°ê³¼ ì²˜ë¦¬
if dfs:
    result = pd.concat(dfs, ignore_index=True)
    print(f"\nâœ… ì´ {len(result)}ê°œ ì„ ìˆ˜ ê¸°ë¡ ìˆ˜ì§‘ ì™„ë£Œ! ({current_season}ì‹œì¦Œ)")
    
    try:
        print("\nğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        print(result.head(10).to_string(index=False))
    except Exception:
        print(result.head(10))
        
    filename = f'kbo_hitters_{current_season}.csv'
    result.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f'\nğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}')
    
else:
    print('âŒ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')

print("\nğŸ í¬ë¡¤ë§ ì™„ë£Œ! ê°ì‚¬í•©ë‹ˆë‹¤.")
driver.quit()